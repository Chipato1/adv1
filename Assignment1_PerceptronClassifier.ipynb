{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47590: Advanced Machine Learning\n",
    "# Assignment 1: Implementing Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Student 1 Name: Carl Fabian Winkler\n",
    "- Student 1 Number: 20207528\n",
    "- Student 2 Name: David Moreno Boras\n",
    "- Student 2 Number: 21200646"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import train_test_split\\n\\nfrom sklearn.utils.validation import check_X_y, check_array, check_is_fitted, check_random_state\\nfrom sklearn.utils.multiclass import unique_labels\\nfrom sklearn import preprocessing\\nfrom sklearn import metrics\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.utils import resample'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted, check_random_state\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: The Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the PerceptronClassifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    def __init__(self, n_in, n_out, activation = 'Sigmoid', init = 'Xavier'):\n",
    "        self.activation = activation\n",
    "        # XW + b = y ; We input more than one sample per pass...\n",
    "        \n",
    "        self.weights = np.zeros((n_in, n_out))\n",
    "        self.biases = np.zeros((n_out))\n",
    "        if init == 'Xavier':\n",
    "            var = np.sqrt(6.0 / (n_in + n_out))\n",
    "            for i in range(n_in):\n",
    "                for j in range(n_out):\n",
    "                      self.weights[i,j] = np.float32(np.random.uniform(-var, var))\n",
    "        \n",
    "        self.d_w = np.zeros(weights.shape)\n",
    "        self.d_b = np.zeros(biases.shape)\n",
    "        #print(\"Weights:\", self.weights.shape)\n",
    "        #print(self.weights) \n",
    "        \n",
    "    def getWeights(self):\n",
    "        return self.weights\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"print(\"X:\", x.shape)\n",
    "        print(x)\n",
    "        print(\"Weights:\", self.weights.shape)\n",
    "        print(self.weights)\"\"\"\n",
    "        z = x @ self.weights + self.biases\n",
    "        \n",
    "        if self.activation == 'Sigmoid':\n",
    "            out = 1 / (1 + np.exp(-z))\n",
    "        elif self.activation == 'ReLu':\n",
    "            out = np.maximum(z, 0)\n",
    "        elif self.activation == 'TanH':\n",
    "            out = np.tanh(z)\n",
    "        else:\n",
    "            out = z\n",
    "        \n",
    "        self.cache = (x, z)\n",
    "        \n",
    "        return out    \n",
    "    \n",
    "    def backward(self, d_out):\n",
    "        inputs, z = self.cache\n",
    "        weight = self.weights\n",
    "        bias = self.biases\n",
    "        \n",
    "        if self.activation == 'Sigmoid':\n",
    "            d_act = d_out * (1 / (1 + np.exp(-z))) * (1 - 1 / (1 + np.exp(-z)))\n",
    "        elif self.activation == 'ReLu':\n",
    "            d_act = d_out * (z > 0)\n",
    "            \n",
    "        elif self.activation == 'TanH':\n",
    "            d_act = d_out * np.square(z)\n",
    "        else:\n",
    "            d_act = z\n",
    "            \n",
    "        d_inputs = d_act @ weight.T\n",
    "        self.d_w = inputs.T @ d_act\n",
    "        self.d_b = d_act.sum(axis=0) \n",
    "        \n",
    "        return d_inputs, self.d_w, self.d_b\n",
    "    \n",
    "    def update_gd_params(self, lr):\n",
    "        self.weights = self.weights - lr * self.d_w\n",
    "        self.biases = self.biases - lr * self.d_b\n",
    "\n",
    "class PerceptronClassifier(BaseEstimator, ClassifierMixin, ):\n",
    "    \n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    Attributes\n",
    "    ----------\n",
    "    Notes\n",
    "    -----\n",
    "    See also\n",
    "    --------\n",
    "    Examples\n",
    "    --------\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, in_dim, out_dim, hidden_units, n_layers, activation = 'Sigmoid', \n",
    "                 learning_rate = 0.01, weight_decay = 0, epochs = -1, regularisation = 'L2'):\n",
    "\n",
    "        \"\"\"Setup a Perceptron classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        Returns\n",
    "        -------\n",
    "        \"\"\"     \n",
    "        \n",
    "        self.layers = []\n",
    "        self.lr = learning_rate\n",
    "        self.regularisation = regularisation\n",
    "        \n",
    "        self.layers.append(Layer(in_dim, hidden_units, activation, 'Xavier'))\n",
    "        for l in range(n_layers):\n",
    "            self.layers.append(Layer(hidden_units, hidden_units, activation, 'Xavier'))\n",
    "        self.layers.append(Layer(hidden_units, out_dim, activation, 'Xavier'))\n",
    "        \n",
    "        print(\"Layers:\", len(self.layers))\n",
    "        \n",
    "        # Initialise class variabels\n",
    "    def forward(self, X):\n",
    "        out = self.layers[0].forward(X)\n",
    "        for layer in self.layers[1:]:\n",
    "            out = layer.forward(out)\n",
    "        return out\n",
    "                \n",
    "    def backward(self, in_grad):\n",
    "        i = len(self.layers) - 2 \n",
    "        # d_inputs, _, _ = lay.backward(in_grad)\n",
    "        next_grad = self.layers[i+1].backward(in_grad)\n",
    "        while i >= 1:\n",
    "            next_grad = self.layers[i].backward(next_grad)\n",
    "            i -= 1\n",
    "        \n",
    "    def l2_loss(self, y_hat, pred):\n",
    "        # totalSum = 0\n",
    "        # for layer in self.layers:\n",
    "        #     totalSum = totalSum + np.sum(np.sum(layer.getWeights())\n",
    "        return -y_hat-np.squeeze(pred)\n",
    "\n",
    "    def loss(self, y_hat, pred):\n",
    "        return -np.expand_dims(y_hat-np.squeeze(pred),axis=1)\n",
    "        \n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y, epochs = 30):\n",
    "        # WRITE CODE HERE\n",
    "        for i in range(epochs):\n",
    "            out = self.forward(X)\n",
    "            print(\"Prediction:\",out)\n",
    "            if (self.regularisation == 'L2'):\n",
    "                grad = self.l2_loss(y, out)\n",
    "            else:\n",
    "                grad = self.loss(y, out)\n",
    "            \n",
    "            # Backpropagation\n",
    "            self.backward(grad)\n",
    "            \n",
    "            # Update weights and biases\n",
    "            for layer in self.layers:\n",
    "                layer.update_gd_params(self.lr)\n",
    "        return\n",
    "    \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "    \n",
    "    # The predict_proba function to make a set of predictions for a set of query instances. This returns a set of class distributions.\n",
    "    def predict_proba(self, X):\n",
    "        tmp = self.forward(X)\n",
    "        sum1 = tmp.sum(axis = 1)\n",
    "        out = X.T / sum1\n",
    "        out = out.T\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Diabethic Retinopathy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,1],[2,2]])\n",
    "\n",
    "\n",
    "D = 2\n",
    "N = 2\n",
    "H = 1\n",
    "\n",
    "\n",
    "weights = np.ones((2,1))\n",
    "biases = np.ones((1))  \n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers: 2\n",
      "Prediction: [[0.37464357]]\n",
      "Prediction: [[0.84360968]]\n",
      "Prediction: [[0.88025311]]\n",
      "Prediction: [[0.89881827]]\n",
      "Prediction: [[0.91069826]]\n",
      "Prediction: [[0.91917055]]\n",
      "Prediction: [[0.9256154]]\n",
      "Prediction: [[0.93073483]]\n",
      "Prediction: [[0.93493028]]\n",
      "Prediction: [[0.93845065]]\n",
      "Prediction: [[0.94145982]]\n",
      "Prediction: [[0.94407074]]\n",
      "Prediction: [[0.94636418]]\n",
      "Prediction: [[0.94839967]]\n",
      "Prediction: [[0.95022216]]\n",
      "Prediction: [[0.95186636]]\n",
      "Prediction: [[0.95335952]]\n",
      "Prediction: [[0.9547234]]\n",
      "Prediction: [[0.95597561]]\n",
      "Prediction: [[0.95713058]]\n",
      "Prediction: [[0.95820023]]\n",
      "Prediction: [[0.95919457]]\n",
      "Prediction: [[0.96012201]]\n",
      "Prediction: [[0.96098972]]\n",
      "Prediction: [[0.96180382]]\n",
      "Prediction: [[0.96256961]]\n",
      "Prediction: [[0.96329166]]\n",
      "Prediction: [[0.96397398]]\n",
      "Prediction: [[0.96462007]]\n",
      "Prediction: [[0.96523302]]\n",
      "Prediction: [[0.96581555]]\n",
      "Prediction: [[0.96637011]]\n",
      "Prediction: [[0.96689884]]\n",
      "Prediction: [[0.96740369]]\n",
      "Prediction: [[0.9678864]]\n",
      "Prediction: [[0.96834853]]\n",
      "Prediction: [[0.96879151]]\n",
      "Prediction: [[0.96921661]]\n",
      "Prediction: [[0.969625]]\n",
      "Prediction: [[0.97001775]]\n",
      "Prediction: [[0.97039582]]\n",
      "Prediction: [[0.97076011]]\n",
      "Prediction: [[0.97111142]]\n",
      "Prediction: [[0.97145052]]\n",
      "Prediction: [[0.97177809]]\n",
      "Prediction: [[0.97209476]]\n",
      "Prediction: [[0.97240112]]\n",
      "Prediction: [[0.97269773]]\n",
      "Prediction: [[0.97298508]]\n",
      "Prediction: [[0.97326364]]\n",
      "Prediction: [[0.97353386]]\n",
      "Prediction: [[0.97379614]]\n",
      "Prediction: [[0.97405086]]\n",
      "Prediction: [[0.97429837]]\n",
      "Prediction: [[0.97453901]]\n",
      "Prediction: [[0.97477309]]\n",
      "Prediction: [[0.9750009]]\n",
      "Prediction: [[0.97522272]]\n",
      "Prediction: [[0.97543879]]\n",
      "Prediction: [[0.97564937]]\n",
      "Prediction: [[0.97585469]]\n",
      "Prediction: [[0.97605495]]\n",
      "Prediction: [[0.97625036]]\n",
      "Prediction: [[0.97644112]]\n",
      "Prediction: [[0.9766274]]\n",
      "Prediction: [[0.97680937]]\n",
      "Prediction: [[0.97698721]]\n",
      "Prediction: [[0.97716106]]\n",
      "Prediction: [[0.97733106]]\n",
      "Prediction: [[0.97749737]]\n",
      "Prediction: [[0.97766011]]\n",
      "Prediction: [[0.9778194]]\n",
      "Prediction: [[0.97797536]]\n",
      "Prediction: [[0.97812812]]\n",
      "Prediction: [[0.97827777]]\n",
      "Prediction: [[0.97842443]]\n",
      "Prediction: [[0.97856818]]\n",
      "Prediction: [[0.97870912]]\n",
      "Prediction: [[0.97884735]]\n",
      "Prediction: [[0.97898295]]\n",
      "Prediction: [[0.979116]]\n",
      "Prediction: [[0.97924657]]\n",
      "Prediction: [[0.97937476]]\n",
      "Prediction: [[0.97950062]]\n",
      "Prediction: [[0.97962422]]\n",
      "Prediction: [[0.97974564]]\n",
      "Prediction: [[0.97986493]]\n",
      "Prediction: [[0.97998216]]\n",
      "Prediction: [[0.98009739]]\n",
      "Prediction: [[0.98021067]]\n",
      "Prediction: [[0.98032205]]\n",
      "Prediction: [[0.98043159]]\n",
      "Prediction: [[0.98053934]]\n",
      "Prediction: [[0.98064535]]\n",
      "Prediction: [[0.98074966]]\n",
      "Prediction: [[0.98085232]]\n",
      "Prediction: [[0.98095336]]\n",
      "Prediction: [[0.98105284]]\n",
      "Prediction: [[0.98115079]]\n",
      "Prediction: [[0.98124725]]\n",
      "Prediction: [[0.98134226]]\n",
      "Prediction: [[0.98143585]]\n",
      "Prediction: [[0.98152806]]\n",
      "Prediction: [[0.98161892]]\n",
      "Prediction: [[0.98170847]]\n",
      "Prediction: [[0.98179673]]\n",
      "Prediction: [[0.98188374]]\n",
      "Prediction: [[0.98196953]]\n",
      "Prediction: [[0.98205411]]\n",
      "Prediction: [[0.98213753]]\n",
      "Prediction: [[0.98221981]]\n",
      "Prediction: [[0.98230097]]\n",
      "Prediction: [[0.98238104]]\n",
      "Prediction: [[0.98246004]]\n",
      "Prediction: [[0.982538]]\n",
      "Prediction: [[0.98261493]]\n",
      "Prediction: [[0.98269087]]\n",
      "Prediction: [[0.98276583]]\n",
      "Prediction: [[0.98283983]]\n",
      "Prediction: [[0.9829129]]\n",
      "Prediction: [[0.98298504]]\n",
      "Prediction: [[0.98305629]]\n",
      "Prediction: [[0.98312666]]\n",
      "Prediction: [[0.98319617]]\n",
      "Prediction: [[0.98326483]]\n",
      "Prediction: [[0.98333267]]\n",
      "Prediction: [[0.98339969]]\n",
      "Prediction: [[0.98346592]]\n",
      "Prediction: [[0.98353137]]\n",
      "Prediction: [[0.98359606]]\n",
      "Prediction: [[0.98365999]]\n",
      "Prediction: [[0.98372319]]\n",
      "Prediction: [[0.98378567]]\n",
      "Prediction: [[0.98384744]]\n",
      "Prediction: [[0.98390851]]\n",
      "Prediction: [[0.9839689]]\n",
      "Prediction: [[0.98402863]]\n",
      "Prediction: [[0.98408769]]\n",
      "Prediction: [[0.98414612]]\n",
      "Prediction: [[0.9842039]]\n",
      "Prediction: [[0.98426107]]\n",
      "Prediction: [[0.98431762]]\n",
      "Prediction: [[0.98437358]]\n",
      "Prediction: [[0.98442894]]\n",
      "Prediction: [[0.98448373]]\n",
      "Prediction: [[0.98453794]]\n",
      "Prediction: [[0.9845916]]\n",
      "Prediction: [[0.9846447]]\n",
      "Prediction: [[0.98469727]]\n",
      "Prediction: [[0.9847493]]\n",
      "Prediction: [[0.98480081]]\n",
      "Prediction: [[0.98485181]]\n",
      "Prediction: [[0.9849023]]\n",
      "Prediction: [[0.98495229]]\n",
      "Prediction: [[0.98500179]]\n",
      "Prediction: [[0.98505081]]\n",
      "Prediction: [[0.98509936]]\n",
      "Prediction: [[0.98514744]]\n",
      "Prediction: [[0.98519506]]\n",
      "Prediction: [[0.98524223]]\n",
      "Prediction: [[0.98528896]]\n",
      "Prediction: [[0.98533525]]\n",
      "Prediction: [[0.98538111]]\n",
      "Prediction: [[0.98542654]]\n",
      "Prediction: [[0.98547156]]\n",
      "Prediction: [[0.98551616]]\n",
      "Prediction: [[0.98556036]]\n",
      "Prediction: [[0.98560416]]\n",
      "Prediction: [[0.98564757]]\n",
      "Prediction: [[0.98569059]]\n",
      "Prediction: [[0.98573323]]\n",
      "Prediction: [[0.98577549]]\n",
      "Prediction: [[0.98581738]]\n",
      "Prediction: [[0.98585891]]\n",
      "Prediction: [[0.98590007]]\n",
      "Prediction: [[0.98594088]]\n",
      "Prediction: [[0.98598135]]\n",
      "Prediction: [[0.98602146]]\n",
      "Prediction: [[0.98606124]]\n",
      "Prediction: [[0.98610068]]\n",
      "Prediction: [[0.9861398]]\n",
      "Prediction: [[0.98617858]]\n",
      "Prediction: [[0.98621705]]\n",
      "Prediction: [[0.9862552]]\n",
      "Prediction: [[0.98629303]]\n",
      "Prediction: [[0.98633056]]\n",
      "Prediction: [[0.98636778]]\n",
      "Prediction: [[0.9864047]]\n",
      "Prediction: [[0.98644133]]\n",
      "Prediction: [[0.98647766]]\n",
      "Prediction: [[0.98651371]]\n",
      "Prediction: [[0.98654947]]\n",
      "Prediction: [[0.98658495]]\n",
      "Prediction: [[0.98662015]]\n",
      "Prediction: [[0.98665508]]\n",
      "Prediction: [[0.98668974]]\n",
      "Prediction: [[0.98672413]]\n",
      "Prediction: [[0.98675826]]\n",
      "Prediction: [[0.98679213]]\n",
      "Prediction: [[0.98682574]]\n",
      "Prediction: [[0.9868591]]\n",
      "Prediction: [[0.98689221]]\n",
      "Prediction: [[0.98692507]]\n",
      "Prediction: [[0.98695768]]\n",
      "Prediction: [[0.98699006]]\n",
      "Prediction: [[0.9870222]]\n",
      "Prediction: [[0.9870541]]\n",
      "Prediction: [[0.98708577]]\n",
      "Prediction: [[0.98711721]]\n",
      "Prediction: [[0.98714842]]\n",
      "Prediction: [[0.98717941]]\n",
      "Prediction: [[0.98721018]]\n",
      "Prediction: [[0.98724073]]\n",
      "Prediction: [[0.98727106]]\n",
      "Prediction: [[0.98730118]]\n",
      "Prediction: [[0.98733109]]\n",
      "Prediction: [[0.98736079]]\n",
      "Prediction: [[0.98739028]]\n",
      "Prediction: [[0.98741956]]\n",
      "Prediction: [[0.98744865]]\n",
      "Prediction: [[0.98747754]]\n",
      "Prediction: [[0.98750623]]\n",
      "Prediction: [[0.98753472]]\n",
      "Prediction: [[0.98756302]]\n",
      "Prediction: [[0.98759113]]\n",
      "Prediction: [[0.98761906]]\n",
      "Prediction: [[0.98764679]]\n",
      "Prediction: [[0.98767435]]\n",
      "Prediction: [[0.98770172]]\n",
      "Prediction: [[0.98772891]]\n",
      "Prediction: [[0.98775592]]\n",
      "Prediction: [[0.98778275]]\n",
      "Prediction: [[0.98780941]]\n",
      "Prediction: [[0.9878359]]\n",
      "Prediction: [[0.98786222]]\n",
      "Prediction: [[0.98788836]]\n",
      "Prediction: [[0.98791435]]\n",
      "Prediction: [[0.98794016]]\n",
      "Prediction: [[0.98796581]]\n",
      "Prediction: [[0.9879913]]\n",
      "Prediction: [[0.98801663]]\n",
      "Prediction: [[0.9880418]]\n",
      "Prediction: [[0.98806682]]\n",
      "Prediction: [[0.98809168]]\n",
      "Prediction: [[0.98811638]]\n",
      "Prediction: [[0.98814094]]\n",
      "Prediction: [[0.98816534]]\n",
      "Prediction: [[0.98818959]]\n",
      "Prediction: [[0.9882137]]\n",
      "Prediction: [[0.98823766]]\n",
      "Prediction: [[0.98826147]]\n",
      "Prediction: [[0.98828515]]\n",
      "Prediction: [[0.98830868]]\n",
      "Prediction: [[0.98833207]]\n",
      "Prediction: [[0.98835532]]\n",
      "Prediction: [[0.98837843]]\n",
      "Prediction: [[0.98840141]]\n",
      "Prediction: [[0.98842425]]\n",
      "Prediction: [[0.98844696]]\n",
      "Prediction: [[0.98846954]]\n",
      "Prediction: [[0.98849199]]\n",
      "Prediction: [[0.9885143]]\n",
      "Prediction: [[0.98853649]]\n",
      "Prediction: [[0.98855855]]\n",
      "Prediction: [[0.98858049]]\n",
      "Prediction: [[0.9886023]]\n",
      "Prediction: [[0.98862398]]\n",
      "Prediction: [[0.98864554]]\n",
      "Prediction: [[0.98866699]]\n",
      "Prediction: [[0.98868831]]\n",
      "Prediction: [[0.98870951]]\n",
      "Prediction: [[0.9887306]]\n",
      "Prediction: [[0.98875156]]\n",
      "Prediction: [[0.98877242]]\n",
      "Prediction: [[0.98879315]]\n",
      "Prediction: [[0.98881378]]\n",
      "Prediction: [[0.98883429]]\n",
      "Prediction: [[0.98885468]]\n",
      "Prediction: [[0.98887497]]\n",
      "Prediction: [[0.98889515]]\n",
      "Prediction: [[0.98891522]]\n",
      "Prediction: [[0.98893518]]\n",
      "Prediction: [[0.98895504]]\n",
      "Prediction: [[0.98897479]]\n",
      "Prediction: [[0.98899443]]\n",
      "Prediction: [[0.98901397]]\n",
      "Prediction: [[0.98903341]]\n",
      "Prediction: [[0.98905275]]\n",
      "Prediction: [[0.98907198]]\n",
      "Prediction: [[0.98909111]]\n",
      "Prediction: [[0.98911015]]\n",
      "Prediction: [[0.98912908]]\n",
      "Prediction: [[0.98914792]]\n",
      "Prediction: [[0.98916666]]\n",
      "Prediction: [[0.9891853]]\n",
      "Prediction: [[0.98920385]]\n",
      "Prediction: [[0.98922231]]\n",
      "Prediction: [[0.98924067]]\n",
      "Prediction: [[0.98925894]]\n",
      "Prediction: [[0.98927711]]\n",
      "Prediction: [[0.9892952]]\n",
      "Prediction: [[0.98931319]]\n",
      "Prediction: [[0.98933109]]\n",
      "Prediction: [[0.98934891]]\n",
      "Prediction: [[0.98936663]]\n",
      "Prediction: [[0.98938427]]\n",
      "Prediction: [[0.98940182]]\n",
      "Prediction: [[0.98941929]]\n",
      "Prediction: [[0.98943667]]\n",
      "Prediction: [[0.98945396]]\n",
      "Prediction: [[0.98947117]]\n",
      "Prediction: [[0.9894883]]\n",
      "Prediction: [[0.98950535]]\n",
      "Prediction: [[0.98952231]]\n",
      "Prediction: [[0.98953919]]\n",
      "Prediction: [[0.98955599]]\n",
      "Prediction: [[0.98957271]]\n",
      "Prediction: [[0.98958935]]\n",
      "Prediction: [[0.98960591]]\n",
      "Prediction: [[0.98962239]]\n",
      "Prediction: [[0.9896388]]\n",
      "Prediction: [[0.98965513]]\n",
      "Prediction: [[0.98967138]]\n",
      "Prediction: [[0.98968755]]\n",
      "Prediction: [[0.98970365]]\n",
      "Prediction: [[0.98971968]]\n",
      "Prediction: [[0.98973563]]\n",
      "Prediction: [[0.98975151]]\n",
      "Prediction: [[0.98976731]]\n",
      "Prediction: [[0.98978305]]\n",
      "Prediction: [[0.98979871]]\n",
      "Prediction: [[0.9898143]]\n",
      "Prediction: [[0.98982982]]\n",
      "Prediction: [[0.98984526]]\n",
      "Prediction: [[0.98986064]]\n",
      "Prediction: [[0.98987595]]\n",
      "Prediction: [[0.98989119]]\n",
      "Prediction: [[0.98990636]]\n",
      "Prediction: [[0.98992147]]\n",
      "Prediction: [[0.9899365]]\n",
      "Prediction: [[0.98995147]]\n",
      "Prediction: [[0.98996638]]\n",
      "Prediction: [[0.98998122]]\n",
      "Prediction: [[0.98999599]]\n",
      "Prediction: [[0.9900107]]\n",
      "Prediction: [[0.99002534]]\n",
      "Prediction: [[0.99003992]]\n",
      "Prediction: [[0.99005444]]\n",
      "Prediction: [[0.99006889]]\n",
      "Prediction: [[0.99008328]]\n",
      "Prediction: [[0.99009761]]\n",
      "Prediction: [[0.99011188]]\n",
      "Prediction: [[0.99012609]]\n",
      "Prediction: [[0.99014023]]\n",
      "Prediction: [[0.99015432]]\n",
      "Prediction: [[0.99016835]]\n",
      "Prediction: [[0.99018231]]\n",
      "Prediction: [[0.99019622]]\n",
      "Prediction: [[0.99021007]]\n",
      "Prediction: [[0.99022386]]\n",
      "Prediction: [[0.99023759]]\n",
      "Prediction: [[0.99025127]]\n",
      "Prediction: [[0.99026489]]\n",
      "Prediction: [[0.99027845]]\n",
      "Prediction: [[0.99029195]]\n",
      "Prediction: [[0.9903054]]\n",
      "Prediction: [[0.9903188]]\n",
      "Prediction: [[0.99033214]]\n",
      "Prediction: [[0.99034542]]\n",
      "Prediction: [[0.99035865]]\n",
      "Prediction: [[0.99037183]]\n",
      "Prediction: [[0.99038495]]\n",
      "Prediction: [[0.99039802]]\n",
      "Prediction: [[0.99041104]]\n",
      "Prediction: [[0.990424]]\n",
      "Prediction: [[0.99043691]]\n",
      "Prediction: [[0.99044977]]\n",
      "Prediction: [[0.99046258]]\n",
      "Prediction: [[0.99047534]]\n",
      "Prediction: [[0.99048805]]\n",
      "Prediction: [[0.9905007]]\n",
      "Prediction: [[0.99051331]]\n",
      "Prediction: [[0.99052587]]\n",
      "Prediction: [[0.99053837]]\n",
      "Prediction: [[0.99055083]]\n",
      "Prediction: [[0.99056324]]\n",
      "Prediction: [[0.9905756]]\n",
      "Prediction: [[0.99058791]]\n",
      "Prediction: [[0.99060018]]\n",
      "Prediction: [[0.9906124]]\n",
      "Prediction: [[0.99062457]]\n",
      "Prediction: [[0.99063669]]\n",
      "Prediction: [[0.99064876]]\n",
      "Prediction: [[0.99066079]]\n",
      "Prediction: [[0.99067278]]\n",
      "Prediction: [[0.99068472]]\n",
      "Prediction: [[0.99069661]]\n",
      "Prediction: [[0.99070846]]\n",
      "Prediction: [[0.99072026]]\n",
      "Prediction: [[0.99073202]]\n",
      "Prediction: [[0.99074373]]\n",
      "Prediction: [[0.9907554]]\n",
      "Prediction: [[0.99076702]]\n",
      "Prediction: [[0.99077861]]\n",
      "Prediction: [[0.99079015]]\n",
      "Prediction: [[0.99080164]]\n",
      "Prediction: [[0.9908131]]\n",
      "Prediction: [[0.99082451]]\n",
      "Prediction: [[0.99083587]]\n",
      "Prediction: [[0.9908472]]\n",
      "Prediction: [[0.99085849]]\n",
      "Prediction: [[0.99086973]]\n",
      "Prediction: [[0.99088093]]\n",
      "Prediction: [[0.99089209]]\n",
      "Prediction: [[0.99090321]]\n",
      "Prediction: [[0.99091429]]\n",
      "Prediction: [[0.99092534]]\n",
      "Prediction: [[0.99093634]]\n",
      "Prediction: [[0.9909473]]\n",
      "Prediction: [[0.99095822]]\n",
      "Prediction: [[0.9909691]]\n",
      "Prediction: [[0.99097994]]\n",
      "Prediction: [[0.99099075]]\n",
      "Prediction: [[0.99100151]]\n",
      "Prediction: [[0.99101224]]\n",
      "Prediction: [[0.99102293]]\n",
      "Prediction: [[0.99103358]]\n",
      "Prediction: [[0.99104419]]\n",
      "Prediction: [[0.99105477]]\n",
      "Prediction: [[0.99106531]]\n",
      "Prediction: [[0.99107581]]\n",
      "Prediction: [[0.99108628]]\n",
      "Prediction: [[0.99109671]]\n",
      "Prediction: [[0.9911071]]\n",
      "Prediction: [[0.99111745]]\n",
      "Prediction: [[0.99112778]]\n",
      "Prediction: [[0.99113806]]\n",
      "Prediction: [[0.99114831]]\n",
      "Prediction: [[0.99115852]]\n",
      "Prediction: [[0.9911687]]\n",
      "Prediction: [[0.99117885]]\n",
      "Prediction: [[0.99118896]]\n",
      "Prediction: [[0.99119903]]\n",
      "Prediction: [[0.99120907]]\n",
      "Prediction: [[0.99121908]]\n",
      "Prediction: [[0.99122905]]\n",
      "Prediction: [[0.99123899]]\n",
      "Prediction: [[0.99124889]]\n",
      "Prediction: [[0.99125877]]\n",
      "Prediction: [[0.99126861]]\n",
      "Prediction: [[0.99127841]]\n",
      "Prediction: [[0.99128818]]\n",
      "Prediction: [[0.99129792]]\n",
      "Prediction: [[0.99130763]]\n",
      "Prediction: [[0.99131731]]\n",
      "Prediction: [[0.99132695]]\n",
      "Prediction: [[0.99133656]]\n",
      "Prediction: [[0.99134614]]\n",
      "Prediction: [[0.99135569]]\n",
      "Prediction: [[0.99136521]]\n",
      "Prediction: [[0.9913747]]\n",
      "Prediction: [[0.99138415]]\n",
      "Prediction: [[0.99139357]]\n",
      "Prediction: [[0.99140297]]\n",
      "Prediction: [[0.99141233]]\n",
      "Prediction: [[0.99142166]]\n",
      "Prediction: [[0.99143096]]\n",
      "Prediction: [[0.99144024]]\n",
      "Prediction: [[0.99144948]]\n",
      "Prediction: [[0.99145869]]\n",
      "Prediction: [[0.99146787]]\n",
      "Prediction: [[0.99147703]]\n",
      "Prediction: [[0.99148615]]\n",
      "Prediction: [[0.99149525]]\n",
      "Prediction: [[0.99150431]]\n",
      "Prediction: [[0.99151335]]\n",
      "Prediction: [[0.99152236]]\n",
      "Prediction: [[0.99153134]]\n",
      "Prediction: [[0.99154029]]\n",
      "Prediction: [[0.99154922]]\n",
      "Prediction: [[0.99155811]]\n",
      "Prediction: [[0.99156698]]\n",
      "Prediction: [[0.99157582]]\n",
      "Prediction: [[0.99158463]]\n",
      "Prediction: [[0.99159342]]\n",
      "Prediction: [[0.99160218]]\n",
      "Prediction: [[0.99161091]]\n",
      "Prediction: [[0.99161961]]\n",
      "Prediction: [[0.99162829]]\n",
      "Prediction: [[0.99163694]]\n",
      "Prediction: [[0.99164556]]\n",
      "Prediction: [[0.99165416]]\n",
      "Prediction: [[0.99166273]]\n",
      "Prediction: [[0.99167127]]\n",
      "Prediction: [[0.99167979]]\n",
      "Prediction: [[0.99168828]]\n",
      "Prediction: [[0.99169675]]\n",
      "Prediction: [[0.99170519]]\n",
      "Prediction: [[0.9917136]]\n",
      "Prediction: [[0.99172199]]\n",
      "Prediction: [[0.99173036]]\n",
      "Prediction: [[0.9917387]]\n",
      "Prediction: [[0.99174701]]\n",
      "Prediction: [[0.9917553]]\n",
      "Prediction: [[0.99176356]]\n",
      "Prediction: [[0.9917718]]\n",
      "Prediction: [[0.99178002]]\n",
      "Prediction: [[0.99178821]]\n",
      "Prediction: [[0.99179638]]\n",
      "Prediction: [[0.99180452]]\n",
      "Prediction: [[0.99181264]]\n",
      "Prediction: [[0.99182073]]\n",
      "Prediction: [[0.9918288]]\n",
      "Prediction: [[0.99183685]]\n",
      "Prediction: [[0.99184487]]\n",
      "Prediction: [[0.99185287]]\n",
      "Prediction: [[0.99186084]]\n",
      "Prediction: [[0.9918688]]\n",
      "Prediction: [[0.99187673]]\n",
      "Prediction: [[0.99188463]]\n",
      "Prediction: [[0.99189252]]\n",
      "Prediction: [[0.99190038]]\n",
      "Prediction: [[0.99190822]]\n",
      "Prediction: [[0.99191603]]\n",
      "Prediction: [[0.99192383]]\n",
      "Prediction: [[0.9919316]]\n",
      "Prediction: [[0.99193934]]\n",
      "Prediction: [[0.99194707]]\n",
      "Prediction: [[0.99195477]]\n",
      "Prediction: [[0.99196246]]\n",
      "Prediction: [[0.99197012]]\n",
      "Prediction: [[0.99197776]]\n",
      "Prediction: [[0.99198537]]\n",
      "Prediction: [[0.99199297]]\n",
      "Prediction: [[0.99200054]]\n",
      "Prediction: [[0.99200809]]\n",
      "Prediction: [[0.99201563]]\n",
      "Prediction: [[0.99202314]]\n",
      "Prediction: [[0.99203062]]\n",
      "Prediction: [[0.99203809]]\n",
      "Prediction: [[0.99204554]]\n",
      "Prediction: [[0.99205297]]\n",
      "Prediction: [[0.99206037]]\n",
      "Prediction: [[0.99206776]]\n",
      "Prediction: [[0.99207512]]\n",
      "Prediction: [[0.99208247]]\n",
      "Prediction: [[0.99208979]]\n",
      "Prediction: [[0.9920971]]\n",
      "Prediction: [[0.99210438]]\n",
      "Prediction: [[0.99211164]]\n",
      "Prediction: [[0.99211889]]\n",
      "Prediction: [[0.99212611]]\n",
      "Prediction: [[0.99213332]]\n",
      "Prediction: [[0.9921405]]\n",
      "Prediction: [[0.99214767]]\n",
      "Prediction: [[0.99215481]]\n",
      "Prediction: [[0.99216194]]\n",
      "Prediction: [[0.99216904]]\n",
      "Prediction: [[0.99217613]]\n",
      "Prediction: [[0.9921832]]\n",
      "Prediction: [[0.99219025]]\n",
      "Prediction: [[0.99219728]]\n",
      "Prediction: [[0.99220429]]\n",
      "Prediction: [[0.99221129]]\n",
      "Prediction: [[0.99221826]]\n",
      "Prediction: [[0.99222522]]\n",
      "Prediction: [[0.99223215]]\n",
      "Prediction: [[0.99223907]]\n",
      "Prediction: [[0.99224597]]\n",
      "Prediction: [[0.99225285]]\n",
      "Prediction: [[0.99225972]]\n",
      "Prediction: [[0.99226656]]\n",
      "Prediction: [[0.99227339]]\n",
      "Prediction: [[0.9922802]]\n",
      "Prediction: [[0.99228699]]\n",
      "Prediction: [[0.99229377]]\n",
      "Prediction: [[0.99230052]]\n",
      "Prediction: [[0.99230726]]\n",
      "Prediction: [[0.99231398]]\n",
      "Prediction: [[0.99232069]]\n",
      "Prediction: [[0.99232737]]\n",
      "Prediction: [[0.99233404]]\n",
      "Prediction: [[0.99234069]]\n",
      "Prediction: [[0.99234733]]\n",
      "Prediction: [[0.99235394]]\n",
      "Prediction: [[0.99236054]]\n",
      "Prediction: [[0.99236713]]\n",
      "Prediction: [[0.99237369]]\n",
      "Prediction: [[0.99238024]]\n",
      "Prediction: [[0.99238678]]\n",
      "Prediction: [[0.99239329]]\n",
      "Prediction: [[0.99239979]]\n",
      "Prediction: [[0.99240627]]\n",
      "Prediction: [[0.99241274]]\n",
      "Prediction: [[0.99241919]]\n",
      "Prediction: [[0.99242562]]\n",
      "Prediction: [[0.99243204]]\n",
      "Prediction: [[0.99243844]]\n",
      "Prediction: [[0.99244483]]\n",
      "Prediction: [[0.9924512]]\n",
      "Prediction: [[0.99245755]]\n",
      "Prediction: [[0.99246389]]\n",
      "Prediction: [[0.99247021]]\n",
      "Prediction: [[0.99247651]]\n",
      "Prediction: [[0.9924828]]\n",
      "Prediction: [[0.99248907]]\n",
      "Prediction: [[0.99249533]]\n",
      "Prediction: [[0.99250157]]\n",
      "Prediction: [[0.9925078]]\n",
      "Prediction: [[0.99251401]]\n",
      "Prediction: [[0.99252021]]\n",
      "Prediction: [[0.99252639]]\n",
      "Prediction: [[0.99253256]]\n",
      "Prediction: [[0.99253871]]\n",
      "Prediction: [[0.99254484]]\n",
      "Prediction: [[0.99255096]]\n",
      "Prediction: [[0.99255707]]\n",
      "Prediction: [[0.99256316]]\n",
      "Prediction: [[0.99256924]]\n",
      "Prediction: [[0.9925753]]\n",
      "Prediction: [[0.99258134]]\n",
      "Prediction: [[0.99258737]]\n",
      "Prediction: [[0.99259339]]\n",
      "Prediction: [[0.99259939]]\n",
      "Prediction: [[0.99260538]]\n",
      "Prediction: [[0.99261135]]\n",
      "Prediction: [[0.99261731]]\n",
      "Prediction: [[0.99262326]]\n",
      "Prediction: [[0.99262919]]\n",
      "Prediction: [[0.9926351]]\n",
      "Prediction: [[0.99264101]]\n",
      "Prediction: [[0.99264689]]\n",
      "Prediction: [[0.99265277]]\n",
      "Prediction: [[0.99265863]]\n",
      "Prediction: [[0.99266447]]\n",
      "Prediction: [[0.99267031]]\n",
      "Prediction: [[0.99267612]]\n",
      "Prediction: [[0.99268193]]\n",
      "Prediction: [[0.99268772]]\n",
      "Prediction: [[0.9926935]]\n",
      "Prediction: [[0.99269926]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [[0.99270501]]\n",
      "Prediction: [[0.99271075]]\n",
      "Prediction: [[0.99271647]]\n",
      "Prediction: [[0.99272218]]\n",
      "Prediction: [[0.99272787]]\n",
      "Prediction: [[0.99273356]]\n",
      "Prediction: [[0.99273923]]\n",
      "Prediction: [[0.99274488]]\n",
      "Prediction: [[0.99275053]]\n",
      "Prediction: [[0.99275616]]\n",
      "Prediction: [[0.99276177]]\n",
      "Prediction: [[0.99276738]]\n",
      "Prediction: [[0.99277297]]\n",
      "Prediction: [[0.99277855]]\n",
      "Prediction: [[0.99278411]]\n",
      "Prediction: [[0.99278967]]\n",
      "Prediction: [[0.99279521]]\n",
      "Prediction: [[0.99280073]]\n",
      "Prediction: [[0.99280625]]\n",
      "Prediction: [[0.99281175]]\n",
      "Prediction: [[0.99281724]]\n",
      "Prediction: [[0.99282272]]\n",
      "Prediction: [[0.99282818]]\n",
      "Prediction: [[0.99283363]]\n",
      "Prediction: [[0.99283907]]\n",
      "Prediction: [[0.9928445]]\n",
      "Prediction: [[0.99284991]]\n",
      "Prediction: [[0.99285532]]\n",
      "Prediction: [[0.99286071]]\n",
      "Prediction: [[0.99286609]]\n",
      "Prediction: [[0.99287145]]\n",
      "Prediction: [[0.99287681]]\n",
      "Prediction: [[0.99288215]]\n",
      "Prediction: [[0.99288748]]\n",
      "Prediction: [[0.9928928]]\n",
      "Prediction: [[0.99289811]]\n",
      "Prediction: [[0.9929034]]\n",
      "Prediction: [[0.99290868]]\n",
      "Prediction: [[0.99291396]]\n",
      "Prediction: [[0.99291922]]\n",
      "Prediction: [[0.99292446]]\n",
      "Prediction: [[0.9929297]]\n",
      "Prediction: [[0.99293493]]\n",
      "Prediction: [[0.99294014]]\n",
      "Prediction: [[0.99294534]]\n",
      "Prediction: [[0.99295053]]\n",
      "Prediction: [[0.99295571]]\n",
      "Prediction: [[0.99296088]]\n",
      "Prediction: [[0.99296603]]\n",
      "Prediction: [[0.99297118]]\n",
      "Prediction: [[0.99297631]]\n",
      "Prediction: [[0.99298144]]\n",
      "Prediction: [[0.99298655]]\n",
      "Prediction: [[0.99299165]]\n",
      "Prediction: [[0.99299674]]\n",
      "Prediction: [[0.99300182]]\n",
      "Prediction: [[0.99300688]]\n",
      "Prediction: [[0.99301194]]\n",
      "Prediction: [[0.99301699]]\n"
     ]
    }
   ],
   "source": [
    "#(self, in_dim, out_dim, hidden_units, n_layers,\n",
    "x = np.array([[0,0]])\n",
    "y = np.array([1])\n",
    "clf = PerceptronClassifier(2, 1, 2, 0, regularisation='None', learning_rate = 10,activation='Sigmoid')\n",
    "clf.fit(x, y,epochs=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.array([[0.74552196],\n",
    " [0.76334402]])\n",
    "y = np.ones(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25447804],\n",
       "       [-0.23665598]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(np.squeeze(x)-y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_52221/2417741131.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_52221/320057775.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# WRITE CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularisation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'L2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_52221/320057775.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# Initialise class variabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_52221/320057775.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Weights:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         print(self.weights)\"\"\"\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Sigmoid'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 1)"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the perfomrance of the perceptron classifier on the daibetic retinopathy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47069059])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,1])\n",
    "clf.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(outpur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 & 4: Add Different Activations & Regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reimplement the PerceptronClassifier class adding an activation function option and L2 regularisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronClassifier2(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self):\n",
    "\n",
    "        \"\"\"Setup a Perceptron classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise ranomd state if set\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Initialise class variabels\n",
    "\n",
    "        \n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # WRITE CODE HERE\n",
    "        \n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "\n",
    "        # WRITE CODE HERE\n",
    "    \n",
    "    # The predict_proba function to make a set of predictions for a set of query instances. This returns a set of class distributions.\n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        # WRITE CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and explore it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Reflect on the Performance of the Different Models Evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform hyper-parameter tuning and evaluate models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Diabetic Retiniphaty dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_af = pd.read_csv('messidor_features.csv', na_values='?', index_col = 0)\n",
    "diabetic_af.head()\n",
    "y = diabetic_af.pop('Class').values\n",
    "x_raw = diabetic_af.values\n",
    "print(\"Features: \", x_raw[0:2])\n",
    "print(\"Class: \", y[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict using our classifier\n",
    "\n",
    "With a single split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_raw, y, shuffle=True, train_size = 0.7)\n",
    "clf = PerceptronClassifier(len(x_train[0]), 1, )\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy = metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search\n",
    "\n",
    "Do grid search with the train set, use the test set for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_folds = 5\n",
    "param_grid ={'activation': ['Sigmoid', 'ReLu', 'TanH'], 'regularisation':['None', 'L2']}\n",
    "\n",
    "# Perform the search\n",
    "tuned_perceptron = GridSearchCV(PerceptronClassifier(), \\\n",
    "                            param_grid, cv=cv_folds, verbose = 2, \\\n",
    "                            n_jobs = -1)\n",
    "cross_val_score(clf, x_train, y_train, cv=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
