{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47590: Advanced Machine Learning\n",
    "# Assignment 1: Implementing Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Student 1 Name: Carl Fabian Winkler\n",
    "- Student 1 Number: 20207528\n",
    "- Student 2 Name: David Moreno Boras\n",
    "- Student 2 Number: 21200646"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import train_test_split\\n\\nfrom sklearn.utils.validation import check_X_y, check_array, check_is_fitted, check_random_state\\nfrom sklearn.utils.multiclass import unique_labels\\nfrom sklearn import preprocessing\\nfrom sklearn import metrics\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.utils import resample'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted, check_random_state\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: The Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the PerceptronClassifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    def __init__(self, n_in, n_out, activation = 'Sigmoid', init = 'Xavier'):\n",
    "        self.activation = activation\n",
    "        # XW + b = y ; We input more than one sample per pass...\n",
    "        \n",
    "        self.weights = np.zeros((n_in, n_out))\n",
    "        self.biases = np.zeros((n_out))\n",
    "        if init == 'Xavier':\n",
    "            var = np.sqrt(6.0 / (n_in + n_out))\n",
    "            for i in range(n_in):\n",
    "                for j in range(n_out):\n",
    "                      self.weights[i,j] = np.float32(np.random.uniform(-var, var))\n",
    "        \n",
    "        self.d_w = np.zeros(weights.shape)\n",
    "        self.d_b = np.zeros(biases.shape)\n",
    "        #print(\"Weights:\", self.weights.shape)\n",
    "        #print(self.weights) \n",
    "        \n",
    "    def getWeights(self):\n",
    "        return self.weights\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"print(\"X:\", x.shape)\n",
    "        print(x)\n",
    "        print(\"Weights:\", self.weights.shape)\n",
    "        print(self.weights)\"\"\"\n",
    "        z = x @ self.weights + self.biases\n",
    "        \n",
    "        if self.activation == 'Sigmoid':\n",
    "            out = 1 / (1 + np.exp(-z))\n",
    "        elif self.activation == 'ReLu':\n",
    "            out = np.maximum(z, 0)\n",
    "        elif self.activation == 'TanH':\n",
    "            out = np.tanh(z)\n",
    "        else:\n",
    "            out = z\n",
    "        \n",
    "        self.cache = (x, z)\n",
    "        \n",
    "        return out    \n",
    "    \n",
    "    def backward(self, d_out):\n",
    "        inputs, z = self.cache\n",
    "        weight = self.weights\n",
    "        bias = self.biases\n",
    "        \n",
    "        if self.activation == 'Sigmoid':\n",
    "            d_act = d_out * (1 / (1 + np.exp(-z))) * (1 - 1 / (1 + np.exp(-z)))\n",
    "        elif self.activation == 'ReLu':\n",
    "            d_act = d_out * (z > 0)\n",
    "            \n",
    "        elif self.activation == 'TanH':\n",
    "            d_act = d_out * np.square(z)\n",
    "        else:\n",
    "            d_act = z\n",
    "            \n",
    "        d_inputs = d_act @ weight.T\n",
    "        self.d_w = inputs.T @ d_act\n",
    "        self.d_b = d_act.sum(axis=0) \n",
    "        \n",
    "        return d_inputs, self.d_w, self.d_b\n",
    "    \n",
    "    def update_gd_params(self, lr):\n",
    "        self.weights = self.weights - lr * self.d_w\n",
    "        self.biases = self.biases - lr * self.d_b\n",
    "\n",
    "class PerceptronClassifier(BaseEstimator, ClassifierMixin, ):\n",
    "    \n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    Attributes\n",
    "    ----------\n",
    "    Notes\n",
    "    -----\n",
    "    See also\n",
    "    --------\n",
    "    Examples\n",
    "    --------\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, in_dim, out_dim, hidden_units, n_layers, activation = 'Sigmoid', \n",
    "                 learning_rate = 0.01, weight_decay = 0, epochs = -1, regularisation = 'L2'):\n",
    "\n",
    "        \"\"\"Setup a Perceptron classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        Returns\n",
    "        -------\n",
    "        \"\"\"     \n",
    "        \n",
    "        self.layers = []\n",
    "        self.lr = learning_rate\n",
    "        self.regularisation = regularisation\n",
    "        \n",
    "        self.layers.append(Layer(in_dim, hidden_units, activation, 'Xavier'))\n",
    "        for l in range(n_layers):\n",
    "            self.layers.append(Layer(hidden_units, hidden_units, activation, 'Xavier'))\n",
    "        self.layers.append(Layer(hidden_units, out_dim, activation, 'Xavier'))\n",
    "        \n",
    "        print(\"Layers:\", len(self.layers))\n",
    "        \n",
    "        # Initialise class variabels\n",
    "    def forward(self, X):\n",
    "        out = self.layers[0].forward(X)\n",
    "        for layer in self.layers[1:]:\n",
    "            out = layer.forward(out)\n",
    "        return out\n",
    "                \n",
    "    def backward(self, in_grad):\n",
    "        i = len(self.layers) - 2 \n",
    "        # d_inputs, _, _ = lay.backward(in_grad)\n",
    "        next_grad = self.layers[i+1].backward(in_grad)\n",
    "        while i >= 1:\n",
    "            next_grad = self.layers[i].backward(next_grad)\n",
    "            i -= 1\n",
    "        \n",
    "    def l2_loss(self, y_hat, pred):\n",
    "        # totalSum = 0\n",
    "        # for layer in self.layers:\n",
    "        #     totalSum = totalSum + np.sum(np.sum(layer.getWeights())\n",
    "        return -y_hat-np.squeeze(pred)\n",
    "\n",
    "    def loss(self, y_hat, pred):\n",
    "        return -np.expand_dims(y_hat-np.squeeze(pred),axis=1)\n",
    "        \n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y, epochs = 30):\n",
    "        # WRITE CODE HERE\n",
    "        for i in range(epochs):\n",
    "            out = self.forward(X)\n",
    "            print(\"Prediction:\",out)\n",
    "            if (self.regularisation == 'L2'):\n",
    "                grad = self.l2_loss(y, out)\n",
    "            else:\n",
    "                grad = self.loss(y, out)\n",
    "            \n",
    "            # Backpropagation\n",
    "            self.backward(grad)\n",
    "            \n",
    "            # Update weights and biases\n",
    "            for layer in self.layers:\n",
    "                layer.update_gd_params(self.lr)\n",
    "        return\n",
    "    \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "    \n",
    "    # The predict_proba function to make a set of predictions for a set of query instances. This returns a set of class distributions.\n",
    "    def predict_proba(self, X):\n",
    "        tmp = self.forward(X)\n",
    "        sum1 = tmp.sum(axis = 1)\n",
    "        out = X.T / sum1\n",
    "        out = out.T\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Diabethic Retinopathy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,1],[2,2]])\n",
    "\n",
    "\n",
    "D = 2\n",
    "N = 2\n",
    "H = 1\n",
    "\n",
    "\n",
    "weights = np.ones((2,1))\n",
    "biases = np.ones((1))  \n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers: 2\n",
      "Prediction: [[0.42123568]]\n",
      "Prediction: [[0.94568243]]\n",
      "Prediction: [[0.9488184]]\n",
      "Prediction: [[0.95146698]]\n",
      "Prediction: [[0.95374321]]\n",
      "Prediction: [[0.95572721]]\n",
      "Prediction: [[0.9574768]]\n",
      "Prediction: [[0.95903488]]\n",
      "Prediction: [[0.96043411]]\n",
      "Prediction: [[0.9616998]]\n",
      "Prediction: [[0.96285195]]\n",
      "Prediction: [[0.9639066]]\n",
      "Prediction: [[0.96487678]]\n",
      "Prediction: [[0.9657732]]\n",
      "Prediction: [[0.96660475]]\n",
      "Prediction: [[0.9673789]]\n",
      "Prediction: [[0.96810197]]\n",
      "Prediction: [[0.96877932]]\n",
      "Prediction: [[0.96941559]]\n",
      "Prediction: [[0.97001475]]\n",
      "Prediction: [[0.97058029]]\n",
      "Prediction: [[0.97111523]]\n",
      "Prediction: [[0.97162222]]\n",
      "Prediction: [[0.97210363]]\n",
      "Prediction: [[0.97256152]]\n",
      "Prediction: [[0.97299776]]\n",
      "Prediction: [[0.97341398]]\n",
      "Prediction: [[0.97381168]]\n",
      "Prediction: [[0.97419219]]\n",
      "Prediction: [[0.97455671]]\n",
      "Prediction: [[0.97490633]]\n",
      "Prediction: [[0.97524203]]\n",
      "Prediction: [[0.97556472]]\n",
      "Prediction: [[0.9758752]]\n",
      "Prediction: [[0.97617424]]\n",
      "Prediction: [[0.97646251]]\n",
      "Prediction: [[0.97674065]]\n",
      "Prediction: [[0.97700923]]\n",
      "Prediction: [[0.97726879]]\n",
      "Prediction: [[0.97751982]]\n",
      "Prediction: [[0.97776277]]\n",
      "Prediction: [[0.97799808]]\n",
      "Prediction: [[0.97822613]]\n",
      "Prediction: [[0.97844729]]\n",
      "Prediction: [[0.97866189]]\n",
      "Prediction: [[0.97887026]]\n",
      "Prediction: [[0.97907269]]\n",
      "Prediction: [[0.97926946]]\n",
      "Prediction: [[0.97946081]]\n",
      "Prediction: [[0.97964701]]\n",
      "Prediction: [[0.97982827]]\n",
      "Prediction: [[0.98000481]]\n",
      "Prediction: [[0.98017683]]\n",
      "Prediction: [[0.98034452]]\n",
      "Prediction: [[0.98050806]]\n",
      "Prediction: [[0.98066761]]\n",
      "Prediction: [[0.98082334]]\n",
      "Prediction: [[0.98097539]]\n",
      "Prediction: [[0.9811239]]\n",
      "Prediction: [[0.98126902]]\n",
      "Prediction: [[0.98141087]]\n",
      "Prediction: [[0.98154957]]\n",
      "Prediction: [[0.98168523]]\n",
      "Prediction: [[0.98181796]]\n",
      "Prediction: [[0.98194787]]\n",
      "Prediction: [[0.98207506]]\n",
      "Prediction: [[0.98219961]]\n",
      "Prediction: [[0.98232163]]\n",
      "Prediction: [[0.98244118]]\n",
      "Prediction: [[0.98255836]]\n",
      "Prediction: [[0.98267324]]\n",
      "Prediction: [[0.9827859]]\n",
      "Prediction: [[0.98289641]]\n",
      "Prediction: [[0.98300483]]\n",
      "Prediction: [[0.98311122]]\n",
      "Prediction: [[0.98321566]]\n",
      "Prediction: [[0.9833182]]\n",
      "Prediction: [[0.98341889]]\n",
      "Prediction: [[0.9835178]]\n",
      "Prediction: [[0.98361497]]\n",
      "Prediction: [[0.98371045]]\n",
      "Prediction: [[0.9838043]]\n",
      "Prediction: [[0.98389655]]\n",
      "Prediction: [[0.98398726]]\n",
      "Prediction: [[0.98407646]]\n",
      "Prediction: [[0.98416419]]\n",
      "Prediction: [[0.9842505]]\n",
      "Prediction: [[0.98433543]]\n",
      "Prediction: [[0.98441901]]\n",
      "Prediction: [[0.98450127]]\n",
      "Prediction: [[0.98458225]]\n",
      "Prediction: [[0.98466198]]\n",
      "Prediction: [[0.9847405]]\n",
      "Prediction: [[0.98481783]]\n",
      "Prediction: [[0.98489401]]\n",
      "Prediction: [[0.98496906]]\n",
      "Prediction: [[0.98504301]]\n",
      "Prediction: [[0.98511588]]\n",
      "Prediction: [[0.98518771]]\n",
      "Prediction: [[0.98525852]]\n",
      "Prediction: [[0.98532832]]\n",
      "Prediction: [[0.98539715]]\n",
      "Prediction: [[0.98546503]]\n",
      "Prediction: [[0.98553197]]\n",
      "Prediction: [[0.98559801]]\n",
      "Prediction: [[0.98566315]]\n",
      "Prediction: [[0.98572743]]\n",
      "Prediction: [[0.98579085]]\n",
      "Prediction: [[0.98585344]]\n",
      "Prediction: [[0.98591522]]\n",
      "Prediction: [[0.9859762]]\n",
      "Prediction: [[0.9860364]]\n",
      "Prediction: [[0.98609583]]\n",
      "Prediction: [[0.98615452]]\n",
      "Prediction: [[0.98621248]]\n",
      "Prediction: [[0.98626972]]\n",
      "Prediction: [[0.98632625]]\n",
      "Prediction: [[0.9863821]]\n",
      "Prediction: [[0.98643728]]\n",
      "Prediction: [[0.98649179]]\n",
      "Prediction: [[0.98654565]]\n",
      "Prediction: [[0.98659888]]\n",
      "Prediction: [[0.98665149]]\n",
      "Prediction: [[0.98670349]]\n",
      "Prediction: [[0.98675488]]\n",
      "Prediction: [[0.98680569]]\n",
      "Prediction: [[0.98685593]]\n",
      "Prediction: [[0.98690559]]\n",
      "Prediction: [[0.98695471]]\n",
      "Prediction: [[0.98700327]]\n",
      "Prediction: [[0.9870513]]\n",
      "Prediction: [[0.98709881]]\n",
      "Prediction: [[0.9871458]]\n",
      "Prediction: [[0.98719229]]\n",
      "Prediction: [[0.98723827]]\n",
      "Prediction: [[0.98728377]]\n",
      "Prediction: [[0.98732879]]\n",
      "Prediction: [[0.98737333]]\n",
      "Prediction: [[0.98741741]]\n",
      "Prediction: [[0.98746104]]\n",
      "Prediction: [[0.98750422]]\n",
      "Prediction: [[0.98754696]]\n",
      "Prediction: [[0.98758926]]\n",
      "Prediction: [[0.98763114]]\n",
      "Prediction: [[0.9876726]]\n",
      "Prediction: [[0.98771365]]\n",
      "Prediction: [[0.9877543]]\n",
      "Prediction: [[0.98779454]]\n",
      "Prediction: [[0.9878344]]\n",
      "Prediction: [[0.98787387]]\n",
      "Prediction: [[0.98791296]]\n",
      "Prediction: [[0.98795167]]\n",
      "Prediction: [[0.98799002]]\n",
      "Prediction: [[0.98802801]]\n",
      "Prediction: [[0.98806564]]\n",
      "Prediction: [[0.98810292]]\n",
      "Prediction: [[0.98813986]]\n",
      "Prediction: [[0.98817645]]\n",
      "Prediction: [[0.98821271]]\n",
      "Prediction: [[0.98824864]]\n",
      "Prediction: [[0.98828425]]\n",
      "Prediction: [[0.98831954]]\n",
      "Prediction: [[0.98835451]]\n",
      "Prediction: [[0.98838917]]\n",
      "Prediction: [[0.98842352]]\n",
      "Prediction: [[0.98845758]]\n",
      "Prediction: [[0.98849133]]\n",
      "Prediction: [[0.9885248]]\n",
      "Prediction: [[0.98855797]]\n",
      "Prediction: [[0.98859086]]\n",
      "Prediction: [[0.98862348]]\n",
      "Prediction: [[0.98865581]]\n",
      "Prediction: [[0.98868787]]\n",
      "Prediction: [[0.98871966]]\n",
      "Prediction: [[0.98875119]]\n",
      "Prediction: [[0.98878246]]\n",
      "Prediction: [[0.98881347]]\n",
      "Prediction: [[0.98884422]]\n",
      "Prediction: [[0.98887473]]\n",
      "Prediction: [[0.98890498]]\n",
      "Prediction: [[0.98893499]]\n",
      "Prediction: [[0.98896476]]\n",
      "Prediction: [[0.9889943]]\n",
      "Prediction: [[0.9890236]]\n",
      "Prediction: [[0.98905266]]\n",
      "Prediction: [[0.9890815]]\n",
      "Prediction: [[0.98911012]]\n",
      "Prediction: [[0.98913851]]\n",
      "Prediction: [[0.98916668]]\n",
      "Prediction: [[0.98919463]]\n",
      "Prediction: [[0.98922237]]\n",
      "Prediction: [[0.9892499]]\n",
      "Prediction: [[0.98927722]]\n",
      "Prediction: [[0.98930434]]\n",
      "Prediction: [[0.98933125]]\n",
      "Prediction: [[0.98935796]]\n",
      "Prediction: [[0.98938447]]\n",
      "Prediction: [[0.98941078]]\n",
      "Prediction: [[0.98943691]]\n",
      "Prediction: [[0.98946284]]\n",
      "Prediction: [[0.98948858]]\n",
      "Prediction: [[0.98951413]]\n",
      "Prediction: [[0.9895395]]\n",
      "Prediction: [[0.98956469]]\n",
      "Prediction: [[0.9895897]]\n",
      "Prediction: [[0.98961453]]\n",
      "Prediction: [[0.98963918]]\n",
      "Prediction: [[0.98966366]]\n",
      "Prediction: [[0.98968797]]\n",
      "Prediction: [[0.98971211]]\n",
      "Prediction: [[0.98973608]]\n",
      "Prediction: [[0.98975988]]\n",
      "Prediction: [[0.98978352]]\n",
      "Prediction: [[0.989807]]\n",
      "Prediction: [[0.98983032]]\n",
      "Prediction: [[0.98985348]]\n",
      "Prediction: [[0.98987648]]\n",
      "Prediction: [[0.98989933]]\n",
      "Prediction: [[0.98992203]]\n",
      "Prediction: [[0.98994457]]\n",
      "Prediction: [[0.98996696]]\n",
      "Prediction: [[0.98998921]]\n",
      "Prediction: [[0.99001131]]\n",
      "Prediction: [[0.99003326]]\n",
      "Prediction: [[0.99005507]]\n",
      "Prediction: [[0.99007674]]\n",
      "Prediction: [[0.99009827]]\n",
      "Prediction: [[0.99011966]]\n",
      "Prediction: [[0.99014091]]\n",
      "Prediction: [[0.99016203]]\n",
      "Prediction: [[0.99018301]]\n",
      "Prediction: [[0.99020386]]\n",
      "Prediction: [[0.99022458]]\n",
      "Prediction: [[0.99024517]]\n",
      "Prediction: [[0.99026562]]\n",
      "Prediction: [[0.99028596]]\n",
      "Prediction: [[0.99030616]]\n",
      "Prediction: [[0.99032624]]\n",
      "Prediction: [[0.9903462]]\n",
      "Prediction: [[0.99036603]]\n",
      "Prediction: [[0.99038574]]\n",
      "Prediction: [[0.99040534]]\n",
      "Prediction: [[0.99042481]]\n",
      "Prediction: [[0.99044417]]\n",
      "Prediction: [[0.99046341]]\n",
      "Prediction: [[0.99048253]]\n",
      "Prediction: [[0.99050154]]\n",
      "Prediction: [[0.99052044]]\n",
      "Prediction: [[0.99053923]]\n",
      "Prediction: [[0.9905579]]\n",
      "Prediction: [[0.99057647]]\n",
      "Prediction: [[0.99059493]]\n",
      "Prediction: [[0.99061328]]\n",
      "Prediction: [[0.99063152]]\n",
      "Prediction: [[0.99064966]]\n",
      "Prediction: [[0.9906677]]\n",
      "Prediction: [[0.99068563]]\n",
      "Prediction: [[0.99070345]]\n",
      "Prediction: [[0.99072118]]\n",
      "Prediction: [[0.99073881]]\n",
      "Prediction: [[0.99075633]]\n",
      "Prediction: [[0.99077376]]\n",
      "Prediction: [[0.99079109]]\n",
      "Prediction: [[0.99080832]]\n",
      "Prediction: [[0.99082546]]\n",
      "Prediction: [[0.9908425]]\n",
      "Prediction: [[0.99085945]]\n",
      "Prediction: [[0.99087631]]\n",
      "Prediction: [[0.99089307]]\n",
      "Prediction: [[0.99090974]]\n",
      "Prediction: [[0.99092632]]\n",
      "Prediction: [[0.99094281]]\n",
      "Prediction: [[0.99095921]]\n",
      "Prediction: [[0.99097552]]\n",
      "Prediction: [[0.99099175]]\n",
      "Prediction: [[0.99100789]]\n",
      "Prediction: [[0.99102394]]\n",
      "Prediction: [[0.99103991]]\n",
      "Prediction: [[0.99105579]]\n",
      "Prediction: [[0.99107159]]\n",
      "Prediction: [[0.9910873]]\n",
      "Prediction: [[0.99110294]]\n",
      "Prediction: [[0.99111849]]\n",
      "Prediction: [[0.99113396]]\n",
      "Prediction: [[0.99114935]]\n",
      "Prediction: [[0.99116466]]\n",
      "Prediction: [[0.99117989]]\n",
      "Prediction: [[0.99119505]]\n",
      "Prediction: [[0.99121013]]\n",
      "Prediction: [[0.99122513]]\n",
      "Prediction: [[0.99124005]]\n",
      "Prediction: [[0.9912549]]\n",
      "Prediction: [[0.99126967]]\n",
      "Prediction: [[0.99128437]]\n",
      "Prediction: [[0.991299]]\n",
      "Prediction: [[0.99131355]]\n",
      "Prediction: [[0.99132803]]\n",
      "Prediction: [[0.99134244]]\n",
      "Prediction: [[0.99135678]]\n",
      "Prediction: [[0.99137104]]\n",
      "Prediction: [[0.99138524]]\n",
      "Prediction: [[0.99139936]]\n",
      "Prediction: [[0.99141342]]\n",
      "Prediction: [[0.99142741]]\n",
      "Prediction: [[0.99144133]]\n",
      "Prediction: [[0.99145519]]\n",
      "Prediction: [[0.99146898]]\n",
      "Prediction: [[0.9914827]]\n",
      "Prediction: [[0.99149635]]\n",
      "Prediction: [[0.99150994]]\n",
      "Prediction: [[0.99152347]]\n",
      "Prediction: [[0.99153693]]\n",
      "Prediction: [[0.99155033]]\n",
      "Prediction: [[0.99156366]]\n",
      "Prediction: [[0.99157694]]\n",
      "Prediction: [[0.99159015]]\n",
      "Prediction: [[0.99160329]]\n",
      "Prediction: [[0.99161638]]\n",
      "Prediction: [[0.99162941]]\n",
      "Prediction: [[0.99164237]]\n",
      "Prediction: [[0.99165528]]\n",
      "Prediction: [[0.99166813]]\n",
      "Prediction: [[0.99168092]]\n",
      "Prediction: [[0.99169365]]\n",
      "Prediction: [[0.99170632]]\n",
      "Prediction: [[0.99171893]]\n",
      "Prediction: [[0.99173149]]\n",
      "Prediction: [[0.99174399]]\n",
      "Prediction: [[0.99175643]]\n",
      "Prediction: [[0.99176882]]\n",
      "Prediction: [[0.99178116]]\n",
      "Prediction: [[0.99179343]]\n",
      "Prediction: [[0.99180566]]\n",
      "Prediction: [[0.99181783]]\n",
      "Prediction: [[0.99182994]]\n",
      "Prediction: [[0.991842]]\n",
      "Prediction: [[0.99185401]]\n",
      "Prediction: [[0.99186597]]\n",
      "Prediction: [[0.99187787]]\n",
      "Prediction: [[0.99188972]]\n",
      "Prediction: [[0.99190153]]\n",
      "Prediction: [[0.99191327]]\n",
      "Prediction: [[0.99192497]]\n",
      "Prediction: [[0.99193662]]\n",
      "Prediction: [[0.99194822]]\n",
      "Prediction: [[0.99195977]]\n",
      "Prediction: [[0.99197127]]\n",
      "Prediction: [[0.99198272]]\n",
      "Prediction: [[0.99199412]]\n",
      "Prediction: [[0.99200547]]\n",
      "Prediction: [[0.99201678]]\n",
      "Prediction: [[0.99202804]]\n",
      "Prediction: [[0.99203925]]\n",
      "Prediction: [[0.99205041]]\n",
      "Prediction: [[0.99206153]]\n",
      "Prediction: [[0.9920726]]\n",
      "Prediction: [[0.99208362]]\n",
      "Prediction: [[0.9920946]]\n",
      "Prediction: [[0.99210553]]\n",
      "Prediction: [[0.99211642]]\n",
      "Prediction: [[0.99212727]]\n",
      "Prediction: [[0.99213807]]\n",
      "Prediction: [[0.99214882]]\n",
      "Prediction: [[0.99215953]]\n",
      "Prediction: [[0.9921702]]\n",
      "Prediction: [[0.99218083]]\n",
      "Prediction: [[0.99219141]]\n",
      "Prediction: [[0.99220195]]\n",
      "Prediction: [[0.99221244]]\n",
      "Prediction: [[0.9922229]]\n",
      "Prediction: [[0.99223331]]\n",
      "Prediction: [[0.99224368]]\n",
      "Prediction: [[0.99225401]]\n",
      "Prediction: [[0.9922643]]\n",
      "Prediction: [[0.99227455]]\n",
      "Prediction: [[0.99228476]]\n",
      "Prediction: [[0.99229492]]\n",
      "Prediction: [[0.99230505]]\n",
      "Prediction: [[0.99231514]]\n",
      "Prediction: [[0.99232519]]\n",
      "Prediction: [[0.9923352]]\n",
      "Prediction: [[0.99234517]]\n",
      "Prediction: [[0.9923551]]\n",
      "Prediction: [[0.99236499]]\n",
      "Prediction: [[0.99237485]]\n",
      "Prediction: [[0.99238467]]\n",
      "Prediction: [[0.99239445]]\n",
      "Prediction: [[0.99240419]]\n",
      "Prediction: [[0.99241389]]\n",
      "Prediction: [[0.99242356]]\n",
      "Prediction: [[0.99243319]]\n",
      "Prediction: [[0.99244279]]\n",
      "Prediction: [[0.99245235]]\n",
      "Prediction: [[0.99246187]]\n",
      "Prediction: [[0.99247136]]\n",
      "Prediction: [[0.99248081]]\n",
      "Prediction: [[0.99249023]]\n",
      "Prediction: [[0.99249961]]\n",
      "Prediction: [[0.99250895]]\n",
      "Prediction: [[0.99251826]]\n",
      "Prediction: [[0.99252754]]\n",
      "Prediction: [[0.99253678]]\n",
      "Prediction: [[0.99254599]]\n",
      "Prediction: [[0.99255517]]\n",
      "Prediction: [[0.99256431]]\n",
      "Prediction: [[0.99257341]]\n",
      "Prediction: [[0.99258249]]\n",
      "Prediction: [[0.99259153]]\n",
      "Prediction: [[0.99260054]]\n",
      "Prediction: [[0.99260951]]\n",
      "Prediction: [[0.99261846]]\n",
      "Prediction: [[0.99262737]]\n",
      "Prediction: [[0.99263625]]\n",
      "Prediction: [[0.99264509]]\n",
      "Prediction: [[0.99265391]]\n",
      "Prediction: [[0.99266269]]\n",
      "Prediction: [[0.99267145]]\n",
      "Prediction: [[0.99268017]]\n",
      "Prediction: [[0.99268886]]\n",
      "Prediction: [[0.99269752]]\n",
      "Prediction: [[0.99270615]]\n",
      "Prediction: [[0.99271475]]\n",
      "Prediction: [[0.99272332]]\n",
      "Prediction: [[0.99273185]]\n",
      "Prediction: [[0.99274036]]\n",
      "Prediction: [[0.99274884]]\n",
      "Prediction: [[0.99275729]]\n",
      "Prediction: [[0.99276571]]\n",
      "Prediction: [[0.9927741]]\n",
      "Prediction: [[0.99278246]]\n",
      "Prediction: [[0.9927908]]\n",
      "Prediction: [[0.9927991]]\n",
      "Prediction: [[0.99280738]]\n",
      "Prediction: [[0.99281563]]\n",
      "Prediction: [[0.99282384]]\n",
      "Prediction: [[0.99283204]]\n",
      "Prediction: [[0.9928402]]\n",
      "Prediction: [[0.99284834]]\n",
      "Prediction: [[0.99285644]]\n",
      "Prediction: [[0.99286452]]\n",
      "Prediction: [[0.99287258]]\n",
      "Prediction: [[0.9928806]]\n",
      "Prediction: [[0.9928886]]\n",
      "Prediction: [[0.99289658]]\n",
      "Prediction: [[0.99290452]]\n",
      "Prediction: [[0.99291244]]\n",
      "Prediction: [[0.99292034]]\n",
      "Prediction: [[0.9929282]]\n",
      "Prediction: [[0.99293604]]\n",
      "Prediction: [[0.99294386]]\n",
      "Prediction: [[0.99295165]]\n",
      "Prediction: [[0.99295941]]\n",
      "Prediction: [[0.99296715]]\n",
      "Prediction: [[0.99297486]]\n",
      "Prediction: [[0.99298255]]\n",
      "Prediction: [[0.99299021]]\n",
      "Prediction: [[0.99299785]]\n",
      "Prediction: [[0.99300546]]\n",
      "Prediction: [[0.99301305]]\n",
      "Prediction: [[0.99302061]]\n",
      "Prediction: [[0.99302815]]\n",
      "Prediction: [[0.99303567]]\n",
      "Prediction: [[0.99304316]]\n",
      "Prediction: [[0.99305063]]\n",
      "Prediction: [[0.99305807]]\n",
      "Prediction: [[0.99306549]]\n",
      "Prediction: [[0.99307288]]\n",
      "Prediction: [[0.99308025]]\n",
      "Prediction: [[0.9930876]]\n",
      "Prediction: [[0.99309493]]\n",
      "Prediction: [[0.99310223]]\n",
      "Prediction: [[0.99310951]]\n",
      "Prediction: [[0.99311676]]\n",
      "Prediction: [[0.993124]]\n",
      "Prediction: [[0.99313121]]\n",
      "Prediction: [[0.9931384]]\n",
      "Prediction: [[0.99314556]]\n",
      "Prediction: [[0.99315271]]\n",
      "Prediction: [[0.99315983]]\n",
      "Prediction: [[0.99316693]]\n",
      "Prediction: [[0.993174]]\n",
      "Prediction: [[0.99318106]]\n",
      "Prediction: [[0.99318809]]\n",
      "Prediction: [[0.9931951]]\n",
      "Prediction: [[0.99320209]]\n",
      "Prediction: [[0.99320906]]\n",
      "Prediction: [[0.99321601]]\n",
      "Prediction: [[0.99322294]]\n",
      "Prediction: [[0.99322984]]\n",
      "Prediction: [[0.99323673]]\n",
      "Prediction: [[0.99324359]]\n",
      "Prediction: [[0.99325043]]\n",
      "Prediction: [[0.99325725]]\n",
      "Prediction: [[0.99326405]]\n",
      "Prediction: [[0.99327084]]\n",
      "Prediction: [[0.9932776]]\n",
      "Prediction: [[0.99328434]]\n",
      "Prediction: [[0.99329106]]\n",
      "Prediction: [[0.99329776]]\n",
      "Prediction: [[0.99330444]]\n",
      "Prediction: [[0.9933111]]\n",
      "Prediction: [[0.99331774]]\n",
      "Prediction: [[0.99332436]]\n",
      "Prediction: [[0.99333096]]\n",
      "Prediction: [[0.99333754]]\n",
      "Prediction: [[0.9933441]]\n",
      "Prediction: [[0.99335065]]\n",
      "Prediction: [[0.99335717]]\n",
      "Prediction: [[0.99336368]]\n",
      "Prediction: [[0.99337016]]\n",
      "Prediction: [[0.99337663]]\n",
      "Prediction: [[0.99338308]]\n",
      "Prediction: [[0.99338951]]\n",
      "Prediction: [[0.99339592]]\n",
      "Prediction: [[0.99340231]]\n",
      "Prediction: [[0.99340868]]\n",
      "Prediction: [[0.99341504]]\n",
      "Prediction: [[0.99342138]]\n",
      "Prediction: [[0.9934277]]\n",
      "Prediction: [[0.993434]]\n",
      "Prediction: [[0.99344028]]\n",
      "Prediction: [[0.99344654]]\n",
      "Prediction: [[0.99345279]]\n",
      "Prediction: [[0.99345902]]\n",
      "Prediction: [[0.99346523]]\n",
      "Prediction: [[0.99347143]]\n",
      "Prediction: [[0.9934776]]\n",
      "Prediction: [[0.99348376]]\n",
      "Prediction: [[0.9934899]]\n",
      "Prediction: [[0.99349603]]\n",
      "Prediction: [[0.99350214]]\n",
      "Prediction: [[0.99350823]]\n",
      "Prediction: [[0.9935143]]\n",
      "Prediction: [[0.99352036]]\n",
      "Prediction: [[0.99352639]]\n",
      "Prediction: [[0.99353242]]\n",
      "Prediction: [[0.99353842]]\n",
      "Prediction: [[0.99354441]]\n",
      "Prediction: [[0.99355038]]\n",
      "Prediction: [[0.99355634]]\n",
      "Prediction: [[0.99356228]]\n",
      "Prediction: [[0.9935682]]\n",
      "Prediction: [[0.99357411]]\n",
      "Prediction: [[0.99358]]\n",
      "Prediction: [[0.99358588]]\n",
      "Prediction: [[0.99359174]]\n",
      "Prediction: [[0.99359758]]\n",
      "Prediction: [[0.99360341]]\n",
      "Prediction: [[0.99360922]]\n",
      "Prediction: [[0.99361501]]\n",
      "Prediction: [[0.99362079]]\n",
      "Prediction: [[0.99362656]]\n",
      "Prediction: [[0.9936323]]\n",
      "Prediction: [[0.99363804]]\n",
      "Prediction: [[0.99364375]]\n",
      "Prediction: [[0.99364946]]\n",
      "Prediction: [[0.99365514]]\n",
      "Prediction: [[0.99366082]]\n",
      "Prediction: [[0.99366647]]\n",
      "Prediction: [[0.99367211]]\n",
      "Prediction: [[0.99367774]]\n",
      "Prediction: [[0.99368335]]\n",
      "Prediction: [[0.99368895]]\n",
      "Prediction: [[0.99369453]]\n",
      "Prediction: [[0.9937001]]\n",
      "Prediction: [[0.99370565]]\n",
      "Prediction: [[0.99371119]]\n",
      "Prediction: [[0.99371671]]\n",
      "Prediction: [[0.99372222]]\n",
      "Prediction: [[0.99372772]]\n",
      "Prediction: [[0.9937332]]\n",
      "Prediction: [[0.99373866]]\n",
      "Prediction: [[0.99374412]]\n",
      "Prediction: [[0.99374955]]\n",
      "Prediction: [[0.99375498]]\n",
      "Prediction: [[0.99376039]]\n",
      "Prediction: [[0.99376578]]\n",
      "Prediction: [[0.99377116]]\n",
      "Prediction: [[0.99377653]]\n",
      "Prediction: [[0.99378188]]\n",
      "Prediction: [[0.99378723]]\n",
      "Prediction: [[0.99379255]]\n",
      "Prediction: [[0.99379786]]\n",
      "Prediction: [[0.99380316]]\n",
      "Prediction: [[0.99380845]]\n",
      "Prediction: [[0.99381372]]\n",
      "Prediction: [[0.99381898]]\n",
      "Prediction: [[0.99382423]]\n",
      "Prediction: [[0.99382946]]\n",
      "Prediction: [[0.99383468]]\n",
      "Prediction: [[0.99383988]]\n",
      "Prediction: [[0.99384508]]\n",
      "Prediction: [[0.99385026]]\n",
      "Prediction: [[0.99385542]]\n",
      "Prediction: [[0.99386058]]\n",
      "Prediction: [[0.99386572]]\n",
      "Prediction: [[0.99387085]]\n",
      "Prediction: [[0.99387596]]\n",
      "Prediction: [[0.99388106]]\n",
      "Prediction: [[0.99388615]]\n",
      "Prediction: [[0.99389123]]\n",
      "Prediction: [[0.99389629]]\n",
      "Prediction: [[0.99390135]]\n",
      "Prediction: [[0.99390639]]\n",
      "Prediction: [[0.99391141]]\n",
      "Prediction: [[0.99391643]]\n",
      "Prediction: [[0.99392143]]\n",
      "Prediction: [[0.99392642]]\n",
      "Prediction: [[0.9939314]]\n",
      "Prediction: [[0.99393636]]\n",
      "Prediction: [[0.99394132]]\n",
      "Prediction: [[0.99394626]]\n",
      "Prediction: [[0.99395119]]\n",
      "Prediction: [[0.99395611]]\n",
      "Prediction: [[0.99396101]]\n",
      "Prediction: [[0.99396591]]\n",
      "Prediction: [[0.99397079]]\n",
      "Prediction: [[0.99397566]]\n",
      "Prediction: [[0.99398052]]\n",
      "Prediction: [[0.99398536]]\n",
      "Prediction: [[0.9939902]]\n",
      "Prediction: [[0.99399502]]\n",
      "Prediction: [[0.99399983]]\n",
      "Prediction: [[0.99400463]]\n",
      "Prediction: [[0.99400942]]\n",
      "Prediction: [[0.9940142]]\n",
      "Prediction: [[0.99401897]]\n",
      "Prediction: [[0.99402372]]\n",
      "Prediction: [[0.99402846]]\n",
      "Prediction: [[0.9940332]]\n",
      "Prediction: [[0.99403792]]\n",
      "Prediction: [[0.99404263]]\n",
      "Prediction: [[0.99404733]]\n",
      "Prediction: [[0.99405201]]\n",
      "Prediction: [[0.99405669]]\n",
      "Prediction: [[0.99406136]]\n",
      "Prediction: [[0.99406601]]\n",
      "Prediction: [[0.99407066]]\n",
      "Prediction: [[0.99407529]]\n",
      "Prediction: [[0.99407991]]\n",
      "Prediction: [[0.99408452]]\n",
      "Prediction: [[0.99408912]]\n",
      "Prediction: [[0.99409371]]\n",
      "Prediction: [[0.99409829]]\n",
      "Prediction: [[0.99410286]]\n",
      "Prediction: [[0.99410742]]\n",
      "Prediction: [[0.99411197]]\n",
      "Prediction: [[0.9941165]]\n",
      "Prediction: [[0.99412103]]\n",
      "Prediction: [[0.99412555]]\n",
      "Prediction: [[0.99413005]]\n",
      "Prediction: [[0.99413455]]\n",
      "Prediction: [[0.99413904]]\n",
      "Prediction: [[0.99414351]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [[0.99414798]]\n",
      "Prediction: [[0.99415243]]\n",
      "Prediction: [[0.99415688]]\n",
      "Prediction: [[0.99416131]]\n",
      "Prediction: [[0.99416573]]\n",
      "Prediction: [[0.99417015]]\n",
      "Prediction: [[0.99417455]]\n",
      "Prediction: [[0.99417895]]\n",
      "Prediction: [[0.99418333]]\n",
      "Prediction: [[0.99418771]]\n",
      "Prediction: [[0.99419207]]\n",
      "Prediction: [[0.99419643]]\n",
      "Prediction: [[0.99420077]]\n",
      "Prediction: [[0.99420511]]\n",
      "Prediction: [[0.99420944]]\n",
      "Prediction: [[0.99421375]]\n",
      "Prediction: [[0.99421806]]\n",
      "Prediction: [[0.99422236]]\n",
      "Prediction: [[0.99422665]]\n",
      "Prediction: [[0.99423092]]\n",
      "Prediction: [[0.99423519]]\n",
      "Prediction: [[0.99423945]]\n",
      "Prediction: [[0.9942437]]\n",
      "Prediction: [[0.99424794]]\n",
      "Prediction: [[0.99425217]]\n",
      "Prediction: [[0.9942564]]\n",
      "Prediction: [[0.99426061]]\n",
      "Prediction: [[0.99426481]]\n",
      "Prediction: [[0.99426901]]\n",
      "Prediction: [[0.99427319]]\n",
      "Prediction: [[0.99427737]]\n",
      "Prediction: [[0.99428154]]\n",
      "Prediction: [[0.99428569]]\n",
      "Prediction: [[0.99428984]]\n",
      "Prediction: [[0.99429398]]\n",
      "Prediction: [[0.99429811]]\n",
      "Prediction: [[0.99430224]]\n",
      "Prediction: [[0.99430635]]\n",
      "Prediction: [[0.99431045]]\n",
      "Prediction: [[0.99431455]]\n",
      "Prediction: [[0.99431864]]\n",
      "Prediction: [[0.99432271]]\n",
      "Prediction: [[0.99432678]]\n",
      "Prediction: [[0.99433084]]\n",
      "Prediction: [[0.99433489]]\n",
      "Prediction: [[0.99433894]]\n"
     ]
    }
   ],
   "source": [
    "#(self, in_dim, out_dim, hidden_units, n_layers,\n",
    "x = np.array([[0,0]])\n",
    "y = np.array([1])\n",
    "clf = PerceptronClassifier(2, 1, 2, 0, regularisation='None', learning_rate = 10,activation='Sigmoid')\n",
    "clf.fit(x, y,epochs=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.array([[0.74552196],\n",
    " [0.76334402]])\n",
    "y = np.ones(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25447804],\n",
       "       [-0.23665598]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(np.squeeze(x)-y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_52221/2417741131.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_52221/320057775.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# WRITE CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularisation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'L2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_52221/320057775.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# Initialise class variabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_52221/320057775.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Weights:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         print(self.weights)\"\"\"\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Sigmoid'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 1)"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the perfomrance of the perceptron classifier on the daibetic retinopathy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47069059])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,1])\n",
    "clf.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(outpur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 & 4: Add Different Activations & Regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reimplement the PerceptronClassifier class adding an activation function option and L2 regularisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronClassifier2(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self):\n",
    "\n",
    "        \"\"\"Setup a Perceptron classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise ranomd state if set\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Initialise class variabels\n",
    "\n",
    "        \n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # WRITE CODE HERE\n",
    "        \n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "\n",
    "        # WRITE CODE HERE\n",
    "    \n",
    "    # The predict_proba function to make a set of predictions for a set of query instances. This returns a set of class distributions.\n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        # WRITE CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and explore it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Reflect on the Performance of the Different Models Evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform hyper-parameter tuning and evaluate models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Diabetic Retiniphaty dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_af = pd.read_csv('messidor_features.csv', na_values='?', index_col = 0)\n",
    "diabetic_af.head()\n",
    "y = diabetic_af.pop('Class').values\n",
    "x_raw = diabetic_af.values\n",
    "print(\"Features: \", x_raw[0:2])\n",
    "print(\"Class: \", y[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict using our classifier\n",
    "\n",
    "With a single split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_raw, y, shuffle=True, train_size = 0.7)\n",
    "clf = PerceptronClassifier(len(x_train[0]), 1, )\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy = metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search\n",
    "\n",
    "Do grid search with the train set, use the test set for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_folds = 5\n",
    "param_grid ={'activation': ['Sigmoid', 'ReLu', 'TanH'], 'regularisation':['None', 'L2']}\n",
    "\n",
    "# Perform the search\n",
    "tuned_perceptron = GridSearchCV(PerceptronClassifier(), \\\n",
    "                            param_grid, cv=cv_folds, verbose = 2, \\\n",
    "                            n_jobs = -1)\n",
    "cross_val_score(clf, x_train, y_train, cv=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
